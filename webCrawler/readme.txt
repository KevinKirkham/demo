This is a project that I worked on during my internship with Carilion Clinic's web development team. The goal of the project was to identify all SVG images that were in use on a particular domain (specifically velocitycarebycarilion) that did not have title or description tags. This program systematically goes through each page of a site gathering information on the SVGs that it finds and prints that information to the console. 

The basic logic is that there is a queue of pages that the bot will visit. At each page, it gathers the value of the href attribute of the anchor tags that it finds on that page. It then cleans them, removing links to other domains or anything else that doesn't lead to a webpage that isn't the one it is currently on, and then adds it to that queue. I keep track of each page in a tree that recreates the hierarchical structure of a file system in memory as it discovers more pages of the website. With this structure, it can be determined if a discovered page has been visited already or not. This process of requesting webpages if they are new and then gathering hrefs and information on that page's SVG images continues in a loop until no more new hrefs are found. 
